В начале, перед описанием хотелось бы поделиться таким соображением:  алгоритм этот при условии обработки достаточно больших объемов данных, обещает быть в  достаточной мере вычислительно трудоемким.  В связи с этим, вероятно целесообразнее  будет исходно не связываться   с Питоном, а  реализовать какими-то более скоростными, вычислительно мощными средствами.  Об этом хотел бы посоветоваться.  Никаких препятствий для связки с предиктором, который у нас на Питоне не вижу, - просто нужно помнить и заботиться,  чтобы входные и выходные данные  были совместимого, обоюдно понимаемыми двумя программами формата.
Описание:

BEGIN OF PART 1

Берем массив данных – образца того, который  используется  алгоритмом predictor.py   (порядковый № ;  Y ..Ym ;  X1;X2;X3;.. Xn) где и игреки, и  иксы,  (различия между ними,  если вспомнить реформы предиктора, описанные в предыдущем ТЗ  для нас уже  весьма условны)       - то есть значения, идущие начиная со второго столбца и далее,  которые могут браться в исходном, либо в нормированном (да еще и помноженном на прескалеры) виде (сейчас эти подробности - не суть)  и от которых мы образуем    некое «пространство» - в системе координат   размерностью «колич-во(х)+колич-во(y)».
- Раз, относимся к нашим значениям, как к координатам  точек в  прямоугольной системе, и  знаем  метрику этой системы (априорно считаем ее евклидовой) значит, без труда можем   определить расстояния всех точек друг до друга и представить  эти расстояния в виде квадратной матрицы. Образец кода,  для формирования матрицы на основе координат,  я могу найти и предоставить.
Матрицу получили  –  матричные данные (а не исходные данные, которые в массиве)  и будут  главным образом, использоваться нашим алгоритмом.
Далее:
Назначаем СТЕПЕНЬ (*прим.),  в которую возводим расстояния (нормированные и помноженные, либо исходные – смотря по  заданным настройкам)  между всеми точками матрицы и получаем, таким образом,   матрицу расстояний в этой степени; (далее, сокращенно «матрица М»)
Рассчитываем СУММУ  степенных расстояний  для каждой  точки (с остальными точками) и как результат – получаем одномерный вектор  Сумм степенных расстояний  (далее, сокращенно «вектор А»)  размерностью n – в каждой клетке, соответственно -  сумма взятых в степени расстояний до точки n  от остальных n-1  точек. с этим вектором А мы далее  преимущественно и работаем;

END OF PART 1

назначаем ШАГ  сдвига точек -  какую-нибудь весьма малую величину;
начинаем в  матрице М (степенных расстояний)  поочередно  изменять КАЖДОЕ расстояние (ячейку матрицы) на величину ШАГА – только в сторону уменьшения.  Понятно,  что физически – это есть сдвиг точки в сторону какой-либо другой из точек, который будет означать не просто изменение соответствующей ячейки матрицы М, а изменение строки/столбца не пересечении которых она находится – ведь изменятся расстояния и до всех остальных (n-1) точек.  Таким образом: сделали  n*(n-1)   итераций – каждую точку  попробовали сдвинуть относительно (n-1) остальных, и   получили  n*(n-1)   вариантов матрицы М’  а, как следствие и   n*(n-1)   вариантов вектора А’.  Останавливаемся на том варианте сдвига, который дал   ячейку nij   вектора Сумм степенных расстояний (вект.А),  для которой  выражение  [Сумма степенных расстояний(ij) текущая (итоговая по итерации) -  Сумма степенных расстояний(ij) предыдущая]    МИНИМАЛЬНО, из всех ячеек, по всем вариантам вектора.
Тут же сразу можно  вставить оговорку: если число точек (и соотв-но размерность матриц расстояний их друг с другом) столь велики, что выполнение n*(n-1) пересчетов матриц затруднительно, мы стохастической выборкой  снижаем для каждой точки число точек-«корреспондентов» до заданного числа n’, чтобы (по прежнему относительно КАЖДОЙ точки) но сделать уже  только  суммарно  n*(n’-1)    перерасчетов.
Нашли вариант – т.е. получили  некую матрицу М (а  при желании, и вычислили новый вариант исходного массива данных), новый вариант  вектора А;
Повторяем все это, перемещая точки до тех пор, пока не получим  ИЛИ :
- больше ни одного варианта, минимизирующего критерий,
- просто, по завершению заданного числа итераций,
- по условию такого вида:  пока не останется ни одного варианта сдвига какой-либо из точек, который дает уменьшение суммы по вектору А более чем на «В» (какую-то заданную величину,  т.е.)  - и вот этом третьем варианте я думаю на нужно остановиться с выбором – реализовать его.
-------------
*примечание относительно степени:  -  с формулой  - ВСЕ ТОЖЕ САМОЕ, что и в ПРЕДЫДУЩЕМ ТЗ – все оговорки про добавление под скобки дополнительного элемента и смену знака с «плюс» на минус» при использовании отрицательной степени – все тоже самое.

 И,  результирующий этап:
Выбираем точки, сделавшие перемещение   за  все действие алгоритма (от начального своего положения – в конечное местоположение на момент прекращения алгоритма) МЕНЬШЕ   заданной  пороговой величины  (то есть, если мы зададим достаточно большое пороговое значение, то и вообще все точки могут попасть).
Для каждой такой точки делаем по вектору В,  который содержит разность  степенных расстояний  от каждой точки до (n-1) остальных точек  по матрицаM (начальная) и матрицаМ’-конечная.
Рассчитываем  коэф-ты парной корреляции данных векторов (с исключением позиций, связывающих две данные точки)  между собой  и строим матрицу коэффициентов  n*n (матрицаК).
И выполняем ГРУППИРОВКУ точек, на основе матрицы:
 Немного подробнее:
Находим наибольший парный коэфф-т.   Образуем из двух точек, которые им связаны, группу.
Находим следующий по величине парный коэфф-т:  теперь смотрим, - входит ли одна из связываемых им точек  в уже ранее образованную группу (-на данный момент она одна, в общем же случае правильно будет сказать «уже входит в какую-то из  ранее образованных групп») … если НЕ входит, то образуем вторую группу.  Если входит: проверяем не имеет ли  эта новая точка (а также (!!) точки уже объединенные с нею в группу, если таковые уже есть) с какой или какими-либо ранее включенными в эту группу точками коэфф-та НИЖЕ порогового значения.  Если НЕ имеет, то просто присоединяем точку к группе. Если ИМЕЕТ,  то создаем новую группу (или – в общем случае – НЕ ОБЪЕДИНЯЕМ группы).
/далее, как доделаем, добавим еще и группировка по «мягкому правилу» - когда напротив – чтобы точкам оказаться в одной группе. Достаточно им только между собой иметь коэф-т корр.   Достаточно большой положительной величины – без проверок через третьи точки, что даст более монолитную картину групп  - они, очевидно  будут  более крупными и в меньшем количестве /
И так, - пока все  (все отобранные по пороговой величине)  точки, согласно коэф-ту, отражающему тесноту парной связи,  не распределим по конечному числу групп.
Далее остается два заключительных  процесса алгоритма:
1)  Что делаем с точкам, перемещение которых  не позволило им  попасть  в набор первично классифицируемых по группам точек -     для каждой такой точки находим   В КОНЕЧНОМ СОСТОЯНИИ МАТРИЦЫ (а никак уж не в первоначальном) ближайшую –уже проклассифицированную в какую-нибудь группу точку. – Вот к этой  группе (к которой относится эта ближайшая) и относим точку. И так для всех остальных.   – Итак, в итоге чего у нас   теперь вообще  все точки массива  распределены по группам (неверное, кластерами  вернее назвать, ну неважно).
Выводя промежуточный итог, в файле результатов добавляем новый столбец -  «номер группы»  - просто чтобы теперь как-то отличать – куда какая точка попала. Нумерацию групп мне кажется разумнее всего вести по принципу:   группе с максимальным числом точек присваиваем №1 – и далее, нумеруем по убыванию числа точек.
2) Итак  всё  сгруппировано -  вероятно,  еще  после этого не помешает очистить картину от мелких случайных групп.   Задаем минимальный порог количества точек в группе (ну, пусть =6)   ..Пусть, всего в ходе анализа,  образовалось у нас  9 групп.   Находим группу с наименьшим числом точек (если таких больше одной – с одинаковым числом – берем любую произвольно, аналогичного же принципа придерживаемся и далее)    - берем по отдельности каждую точку этой группы.
Смотрим по матрице расстояний,  по   15 (задаваемое значение) точек ИЗ КАЖДОЙ  ГРУППЫ из остальных 8-ми, ближайших к данной точке.   Совершаем   15*8= 120  «проходов» данной точке    вдоль  по 120ти расстояниям до каждой точки с шагом равным   ШАГУ сдвига, заданному для предшествующих стадий алгоритма.  – Смотрим МАКСИМАЛЬНЫЕ  значения функционала (суммы степенных расстояний) которые точка переживает за все шаги перемещения вдоль  по каждому из 120 ребер.   Там где МАКСИМУМ окажется МИНИМАЛЕН  - в ту группу с точкой, принадлежащей которой соединяет найденное ребро, и классифицируем точку.   И так раскидываем все точки выбранной группы.  Затем,  принимаемся за следующую по малости группу.    И так, пока все малые (не проходящие по пороговому значению) группы не распределятся по значимым группам.    Следствия: теоретически,  группы изначально не проходящие по критерию малочисленности в них точек, могут в процессе  отстоять свою сохранность  - за счет пришедших в них точек из еще более малых групп, перейти через критический порог по количеству точек;   теоретически, одна и та же точка может и несколько раз перепрыгнуть из группы в группу – так как изначально она может перейти в группу, тоже относящуюся к малым – затем,  когда дело дойдет уже до этой группы (и окажется, что она так и не выбралась из категории малых) точку перекинет еще в какую-нибудь другую  и т.д.
- По итогам, формируем файлы окончательных результатов, где перешедшие точки (если таковые случатся) соответственно  изменят номер группы.
Всё – весь процесс описан :  формирование матрицы расстояний   – формирование матрицы значений основного функционала (сумм степенных расстояний) на основе которых производится анализ  -  процесс вариации сдвигами точек, чтобы определить направления «скатываний», что напоминает градиентные методы, только в дискретном варианте  -  группировка точек, произведенная на основе анализа выявленных направлений скатываний -  заключительные уточнения в виде «догруппировки» и перегруппировки.
Жду отзывы и вопросы.
